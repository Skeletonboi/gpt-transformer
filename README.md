# gpt2-plus
PyTorch implementation and reproduction of OpenAI GPT-2 architecture (124M scale) with training code from scratch. Future work include instruction finetuning of the model by implementing (Q)Lora and/or IA3 and RAG from scratch.
